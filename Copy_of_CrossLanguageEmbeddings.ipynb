{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samrudh29/IR-HomeWork2/blob/main/Copy_of_CrossLanguageEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDsn_Motja8Q"
      },
      "source": [
        "# Cross-Language Word Embeddings\n",
        "\n",
        "In class, we discussed how we can reduce the dimensionality of word representations from their original vector space to an embedding space on the order of a few hundred dimensions. Different modeling choices for word embeddings may be ultimately evaluated by the effectiveness of classification or retrieval models.\n",
        "\n",
        "In this assignment, however, we will consider another common method of evaluating word embeddings: by judging the usefulness of pairwise distances between words in the embedding space.\n",
        "\n",
        "Follow along with the examples in this notebook, and implement the sections of code flagged with **TODO**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UKm5cPMQ2xHU"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfKjYFDklB4c"
      },
      "source": [
        "We'll start by downloading a plain-text version of the plays of William Shakespeare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Dw3bvl1yf5FB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76c3886-1a47-445f-a803-d2f386c0003c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-18 03:09:08--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt [following]\n",
            "--2022-04-18 03:09:08--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4746840 (4.5M) [text/plain]\n",
            "Saving to: ‘shakespeare_plays.txt.3’\n",
            "\n",
            "shakespeare_plays.t 100%[===================>]   4.53M  3.12MB/s    in 1.5s    \n",
            "\n",
            "2022-04-18 03:09:11 (3.12 MB/s) - ‘shakespeare_plays.txt.3’ saved [4746840/4746840]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/shakespeare_plays.txt\n",
        "lines = [s.split() for s in open('shakespeare_plays.txt')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cZ52pEflKKM"
      },
      "source": [
        "Then, we'll estimate a simple word2vec model on the Shakespeare texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eXT5BNPs_zjM"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzt3lG1-lw33"
      },
      "source": [
        "Even with such a small training set size, you can perform some standard analogy tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i4ruAqhKC3-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46605c2-7fc6-402b-8723-8f8a3ea55622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.8366804122924805),\n",
              " ('york', 0.7633033394813538),\n",
              " ('prince', 0.7581432461738586),\n",
              " ('duke', 0.7502011060714722),\n",
              " ('clarence', 0.7362352609634399),\n",
              " ('warwick', 0.7183172702789307),\n",
              " ('gloucester', 0.714714765548706),\n",
              " ('son', 0.7139991521835327),\n",
              " ('duchess', 0.7110257148742676),\n",
              " ('princess', 0.7104967832565308)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['king','woman'], negative=['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJL45y5emjA9"
      },
      "source": [
        "In other words, we want a vector close to `king` and `woman` but subtracting the dimensions that are important to `man`, i.e., `queen`. Other words are mostly noble titles important in Shakespeare's \"history\" plays.\n",
        "\n",
        "For the rest of this assignment, we will focus on finding words with similar embeddings, both within and across languages. For example, what words are similar to the name of the title character of *Othello*?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1EZGroU0KPyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8368f2e0-5194-4630-9bce-2f1b31b55c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('desdemona', 0.9609982967376709),\n",
              " ('imogen', 0.9471182823181152),\n",
              " ('emilia', 0.9325530529022217),\n",
              " ('lucio', 0.926884114742279),\n",
              " ('iago', 0.9254346489906311),\n",
              " ('troilus', 0.9247232675552368),\n",
              " ('cassio', 0.9240168929100037),\n",
              " ('pisanio', 0.9216016530990601),\n",
              " ('cleopatra', 0.9209161996841431),\n",
              " ('helena', 0.9156539440155029)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.wv.most_similar(positive=['othello'])\n",
        "#model.wv.most_similar(positive=['brutus'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM2BT_7zZle3"
      },
      "source": [
        "If you know the play, you might see some familiar names.\n",
        "\n",
        "This search uses cosine similarity. In the default API, you should see the same similarity between the words `othello` and `desdemona` as in the search results above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-e32-u4zYFda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a987c71-6efb-41fe-e6bb-b404d45a60a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96099836"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model.wv.similarity('othello', 'desdemona')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49DwfAmZ6PU"
      },
      "source": [
        "**TODO**: Your **first task**, therefore, is to implement your own cosine similarity function so that you can reuse it outside of the context of the gensim model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rEj2PqpuZ5xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfd10f5-4fd2-4d98-854d-416f405e435c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9609984"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "## TODO: Implement cosim\n",
        "#Using norm and dot function of numpy for calculation\n",
        "def cosim(v1, v2):\n",
        "  ## return cosine similarity between v1 and v2\n",
        "  mul_v1_v2 = np.dot(v1, v2) \n",
        "  l2_v1 = np.linalg.norm(v1)\n",
        "  l2_v2 = np.linalg.norm(v2)\n",
        "  co_sim = mul_v1_v2/(l2_v1 * l2_v2)\n",
        "  return co_sim\n",
        "\n",
        "## This should give a result similar to model.wv.similarity:\n",
        "cosim(model.wv['othello'], model.wv['desdemona'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TbDqBIHbHfB"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We could collect a lot of human judgments about how similar pairs of words, or pairs of Shakespearean characters, are. Then we could compare different word-embedding models by their ability to replicate these human judgments.\n",
        "\n",
        "If we extend our ambition to multiple languages, however, we can use a word translation task to evaluate word embeddings.\n",
        "\n",
        "We will use a subset of [Facebook AI's FastText cross-language embeddings](https://fasttext.cc/docs/en/aligned-vectors.html) for several languages. Your task will be to compare English both to French, and to *one more language* from the following set: Arabic, German, Portuguese, Russian, Spanish, Vietnamese, and Chinese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FC_FXRnfq1BO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a98e6e-97ee-4f3d-e9d6-84fb343fdecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-18 01:54:19--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec [following]\n",
            "--2022-04-18 01:54:20--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67681172 (65M)\n",
            "Saving to: ‘30k.en.vec.1’\n",
            "\n",
            "30k.en.vec.1        100%[===================>]  64.54M  14.7MB/s    in 5.4s    \n",
            "\n",
            "2022-04-18 01:54:26 (11.9 MB/s) - ‘30k.en.vec.1’ saved [67681172/67681172]\n",
            "\n",
            "--2022-04-18 01:54:26--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec [following]\n",
            "--2022-04-18 01:54:27--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67802327 (65M)\n",
            "Saving to: ‘30k.fr.vec.1’\n",
            "\n",
            "30k.fr.vec.1        100%[===================>]  64.66M  14.0MB/s    in 5.8s    \n",
            "\n",
            "2022-04-18 01:54:33 (11.2 MB/s) - ‘30k.fr.vec.1’ saved [67802327/67802327]\n",
            "\n",
            "--2022-04-18 01:54:34--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ar.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ar.vec [following]\n",
            "--2022-04-18 01:54:34--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ar.vec\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67934954 (65M)\n",
            "Saving to: ‘30k.ar.vec.1’\n",
            "\n",
            "30k.ar.vec.1        100%[===================>]  64.79M  13.1MB/s    in 6.0s    \n",
            "\n",
            "2022-04-18 01:54:41 (10.9 MB/s) - ‘30k.ar.vec.1’ saved [67934954/67934954]\n",
            "\n",
            "--2022-04-18 01:54:41--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.de.vec\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.de.vec [following]\n",
            "--2022-04-18 01:54:41--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.de.vec\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67798315 (65M)\n",
            "Saving to: ‘30k.de.vec.1’\n",
            "\n",
            "30k.de.vec.1        100%[===================>]  64.66M  12.0MB/s    in 6.3s    \n",
            "\n",
            "2022-04-18 01:54:49 (10.2 MB/s) - ‘30k.de.vec.1’ saved [67798315/67798315]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.en.vec\n",
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.fr.vec\n",
        "\n",
        "# TODO: uncomment at least one of these to work with another language\n",
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ar.vec\n",
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.de.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.pt.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.ru.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.es.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.vi.vec\n",
        "# !wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/30k.zh.vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmuIvGpNrJPe"
      },
      "source": [
        "We'll start by loading the word vectors from their textual file format to a dictionary mapping words to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VbWORXkP2Vvn"
      },
      "outputs": [],
      "source": [
        "def vecref(s):\n",
        "  (word, srec) = s.split(' ', 1)\n",
        "  return (word, np.fromstring(srec, sep=' '))\n",
        "\n",
        "def ftvectors(fname):\n",
        "  return { k:v for (k, v) in [vecref(s) for s in open(fname)] if len(v) > 1} \n",
        "\n",
        "envec = ftvectors('30k.en.vec')\n",
        "frvec = ftvectors('30k.fr.vec')\n",
        "\n",
        "# TODO: load vectors for one more language, such as zhvec (Chinese)\n",
        "arvec = ftvectors('30k.ar.vec')\n",
        "devec = ftvectors('30k.de.vec')\n",
        "# ptvec = ftvectors('30k.pt.vec')\n",
        "# ruvec = ftvectors('30k.ru.vec')\n",
        "#esvec = ftvectors('30k.es.vec')\n",
        "# vivec = ftvectors('30k.vi.vec')\n",
        "# zhvec = ftvectors('30k.zh.vec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j88E1JdueZHc"
      },
      "source": [
        "**TODO**: Your next task is to write a simple function that takes a vector and a dictionary of vectors and finds the most similar item in the dictionary. For this assignment, a linear scan through the dictionary using your `cosim` function from above is acceptible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gmdirYOjoSWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef3796f-8137-4df2-fb3b-9989f8418d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('informatique', 0.5023827767603765),\n",
              " ('allemagne', 0.593718413875964),\n",
              " ('matrice', 0.5088361302065517),\n",
              " ('physique', 0.4555543434796394),\n",
              " ('fermentation', 0.3504105196166514)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "## TODO: implement this search function\n",
        "\n",
        "def mostSimilar(vec, vecDict):\n",
        "  ## Use your cosim function from above\n",
        "  mostSimilar_word = ''\n",
        "  similarity_score = 0\n",
        "  \n",
        "  for word in vecDict.keys():\n",
        "    sim = cosim(vec,vecDict.get(word))\n",
        "    if sim > similarity_score:\n",
        "      similarity_score = sim\n",
        "      mostSimilar_word = word\n",
        "  return (mostSimilar_word, similarity_score)\n",
        "\n",
        "## some example searches\n",
        "[mostSimilar(envec[e], frvec) for e in ['computer', 'germany', 'matrix', 'physics', 'yeast']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIKUD5qxpUMB"
      },
      "source": [
        "Some matches make more sense than others. Note that `computer` most closely matches `informatique`, the French term for *computer science*. If you looked further down the list, you would see `ordinateur`, the term for *computer*. This is one weakness of a focus only on embeddings for word *types* independent of context.\n",
        "\n",
        "To evalute cross-language embeddings more broadly, we'll look at a dataset of links between Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "az10sIFwsEUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c6c011-07cc-42b2-9642-a34e1c576617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-18 01:55:13--  http://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab\n",
            "Resolving www.ccs.neu.edu (www.ccs.neu.edu)... 52.70.229.197\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab [following]\n",
            "--2022-04-18 01:55:14--  https://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab\n",
            "Connecting to www.ccs.neu.edu (www.ccs.neu.edu)|52.70.229.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1408915 (1.3M)\n",
            "Saving to: ‘links.tab.2’\n",
            "\n",
            "links.tab.2         100%[===================>]   1.34M  1.48MB/s    in 0.9s    \n",
            "\n",
            "2022-04-18 01:55:16 (1.48 MB/s) - ‘links.tab.2’ saved [1408915/1408915]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.ccs.neu.edu/home/dasmith/courses/cs6200/links.tab\n",
        "links = [s.split() for s in open('links.tab')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqHq0hFCv8NY"
      },
      "source": [
        "This `links` variable consists of triples of `(English term, language, term in that language)`. For example, here is the link between English `academy` and French `académie`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RQ7eusdxtdsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1214119-b3a3-499f-c8fa-ccc7f58c7f57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['academy', 'fr', 'académie']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "links[302]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYEdOQbmwql3"
      },
      "source": [
        "**TODO**: Evaluate the English and French embeddings by computing the proportion of English Wikipedia articles whose corresponding French article is also the closest word in embedding space. Skip English articles not covered by the word embedding dictionary. Since many articles, e.g., about named entities have the same title in English and French, compute the baseline accuracy achieved by simply echoing the English title as if it were French. Remember to iterate only over English Wikipedia articles, not the entire embedding dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJrTJ3ja91Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f35683f-0e6a-4db1-ae43-2f994e0cf6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Line Accuracy: 0.6742324450298915\n",
            "Accuracy: 0.5359205593271862\n"
          ]
        }
      ],
      "source": [
        "## TODO: Compute English-French Wikipedia retrieval accuracy.\n",
        "\n",
        "accuracy = 0\n",
        "baselineAccuracy = 0\n",
        "total_word_count = 0\n",
        "matching_words = 0\n",
        "similar_words = 0\n",
        "for row in links:\n",
        "    if row[1] == 'fr':\n",
        "        if row[0] in envec.keys():\n",
        "            total_word_count += 1\n",
        "            if row[0] == row[2]:\n",
        "                matching_words += 1   \n",
        "            similar, _ = mostSimilar(envec.get(row[0]), frvec)\n",
        "            if similar == row[2]:\n",
        "                similar_words += 1\n",
        "\n",
        "baselineAccuracy = matching_words/total_word_count\n",
        "accuracy = similar_words/total_word_count\n",
        "print('Base Line Accuracy:',baselineAccuracy)\n",
        "print('Accuracy:',accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hqd1buq-OEo"
      },
      "source": [
        "**TODO**: Compute accuracy and baseline (identity function) acccuracy for Englsih and another language besides French. Although the baseline will be lower for languages not written in the Roman alphabet (i.e., Arabic or Chinese), there are still many articles in those languages with headwords written in Roman characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjnKtHya-jmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2872b0-7f0c-4ee6-8e11-bbcf0a5a8747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Line Accuracy: 0.006582155046318869\n",
            "Accuracy: 0.2067284251584593\n"
          ]
        }
      ],
      "source": [
        "## TODO: Compute English-German Wikipedia retrieval accuracy.\n",
        "accuracy = 0\n",
        "baselineAccuracy = 0\n",
        "total_word_count = 0\n",
        "matching_words = 0\n",
        "similar_words = 0\n",
        "for row in links:\n",
        "    if row[1] == 'ar':\n",
        "        if row[0] in envec.keys():\n",
        "            total_word_count += 1\n",
        "            if row[0] == row[2]:\n",
        "                matching_words += 1   \n",
        "            similar, _ = mostSimilar(envec.get(row[0]), arvec)\n",
        "            if similar == row[2]:\n",
        "                similar_words += 1\n",
        "\n",
        "baselineAccuracy = matching_words/total_word_count\n",
        "accuracy = similar_words/total_word_count\n",
        "print('Base Line Accuracy:',baselineAccuracy)\n",
        "print('Accuracy:',accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6z01sufFPJh"
      },
      "source": [
        "**TODO**: Find the 10 nearest neighbors of each English term to compute \"recall at 10\" and \"mean reciprocal rank at 10\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TgAORWTQl0Sl"
      },
      "outputs": [],
      "source": [
        "## TODO: Compute recall@10 and MRR@10 when retrieving 10 nearest neighbors in French and some other language.\n",
        "\n",
        "from itertools import islice\n",
        "import pandas as pd\n",
        "def mostSimilarTop10(vec, vecDict):\n",
        "  similarity_dict = {} \n",
        "  for word in vecDict.keys():\n",
        "    x = cosim(vec,vecDict.get(word))\n",
        "    similarity_dict[word] = x\n",
        "  similarity_dict = dict(sorted(similarity_dict.items(), key=lambda k: k[1], reverse=True))\n",
        "  return (list(similarity_dict.keys())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns = ['word', 'similar_words_collection','translated_word', 'recall_value','reciprocal_rank'])\n",
        "for row in links:\n",
        "  if row[1] == 'fr' :\n",
        "    if row[0] in envec.keys():\n",
        "      similar_words = mostSimilarTop10(envec.get(row[0]), frvec)\n",
        "      df.loc[len(df.index)] = [row[0],similar_words,row[2],999,999] \n"
      ],
      "metadata": {
        "id": "PkMeLS579bnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_values = []\n",
        "reciprocal_rank = []\n",
        "for translated_word, words in zip(df['translated_word'], df['similar_words_collection']):\n",
        "\n",
        "  if translated_word in words:\n",
        "    recall_values.append(1)\n",
        "    reciprocal_rank.append(1 / (words.index(translated_word) + 1))\n",
        "  else:\n",
        "    recall_values.append(0)\n",
        "    reciprocal_rank.append(0)\n",
        "\n",
        "df['recall_value'] = recall_values\n",
        "df['reciprocal_rank'] = reciprocal_rank\n",
        "mean_reciprocal_rank_fr = sum(df['reciprocal_rank'])/len(df)\n",
        "print(mean_reciprocal_rank_fr)"
      ],
      "metadata": {
        "id": "hX5wEHuAeVSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caba2518-ff2a-42d3-d1a9-40db0090cd94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5646970954423574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "LVtRPvu4Al60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e752e6df-fa7d-49a2-b864-c4fcf3618a75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word                           similar_words_collection  \\\n",
              "0     aalborg  [copenhague, odense, göteborg, malmö, trondhei...   \n",
              "1      aarhus  [copenhague, oslo, odense, stockholm, göteborg...   \n",
              "2         aba  [aba, nba, ers, asa, wnba, playoffs, basketbal...   \n",
              "3        abad  [mohammad, bazar, farah, persan, ispahan, téhé...   \n",
              "4     abandon  [abandonner, quitter, renoncer, reprendre, ret...   \n",
              "...       ...                                                ...   \n",
              "9864  zoology  [zoologie, biologie, paléontologie, entomologi...   \n",
              "9865    zorro  [zorro, dracula, bandit, mask, tarzan, serial,...   \n",
              "9866       zu  [zu, bei, und, auf, eine, einer, ein, nach, de...   \n",
              "9867     zulu  [boers, afrikaans, afrika, africain, africaine...   \n",
              "9868   zvezda  [partizan, spartak, fk, cska, dinamo, vk, nk, ...   \n",
              "\n",
              "     translated_word  recall_value  reciprocal_rank  \n",
              "0            aalborg             0              0.0  \n",
              "1             aarhus             0              0.0  \n",
              "2                aba             1              1.0  \n",
              "3               abad             0              0.0  \n",
              "4            abandon             0              0.0  \n",
              "...              ...           ...              ...  \n",
              "9864        zoologie             1              1.0  \n",
              "9865           zorro             1              1.0  \n",
              "9866              zu             1              1.0  \n",
              "9867            zulu             0              0.0  \n",
              "9868          zvezda             0              0.0  \n",
              "\n",
              "[9869 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c851cba-0e77-41f0-9856-915cf5081a68\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>similar_words_collection</th>\n",
              "      <th>translated_word</th>\n",
              "      <th>recall_value</th>\n",
              "      <th>reciprocal_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aalborg</td>\n",
              "      <td>[copenhague, odense, göteborg, malmö, trondhei...</td>\n",
              "      <td>aalborg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aarhus</td>\n",
              "      <td>[copenhague, oslo, odense, stockholm, göteborg...</td>\n",
              "      <td>aarhus</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aba</td>\n",
              "      <td>[aba, nba, ers, asa, wnba, playoffs, basketbal...</td>\n",
              "      <td>aba</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abad</td>\n",
              "      <td>[mohammad, bazar, farah, persan, ispahan, téhé...</td>\n",
              "      <td>abad</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abandon</td>\n",
              "      <td>[abandonner, quitter, renoncer, reprendre, ret...</td>\n",
              "      <td>abandon</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9864</th>\n",
              "      <td>zoology</td>\n",
              "      <td>[zoologie, biologie, paléontologie, entomologi...</td>\n",
              "      <td>zoologie</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9865</th>\n",
              "      <td>zorro</td>\n",
              "      <td>[zorro, dracula, bandit, mask, tarzan, serial,...</td>\n",
              "      <td>zorro</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9866</th>\n",
              "      <td>zu</td>\n",
              "      <td>[zu, bei, und, auf, eine, einer, ein, nach, de...</td>\n",
              "      <td>zu</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9867</th>\n",
              "      <td>zulu</td>\n",
              "      <td>[boers, afrikaans, afrika, africain, africaine...</td>\n",
              "      <td>zulu</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9868</th>\n",
              "      <td>zvezda</td>\n",
              "      <td>[partizan, spartak, fk, cska, dinamo, vk, nk, ...</td>\n",
              "      <td>zvezda</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9869 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c851cba-0e77-41f0-9856-915cf5081a68')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c851cba-0e77-41f0-9856-915cf5081a68 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c851cba-0e77-41f0-9856-915cf5081a68');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO: Compute recall@10 and MRR@10 when retrieving 10 nearest neighbors in German and some other language.\n",
        "df1 = pd.DataFrame(columns = ['word', 'similar_words_collection','translated_word', 'recall_value','reciprocal_rank'])\n",
        "\n",
        "for row in links:\n",
        "  if row[1] == 'ar' :\n",
        "    if row[0] in envec.keys():\n",
        "      similar_words = mostSimilarTop10(envec.get(row[0]), arvec)\n",
        "      df1.loc[len(df1.index)] = [row[0],similar_words,row[2], 999,999] \n",
        "\n",
        "recall_values = []\n",
        "reciprocal_rank = []\n",
        "for translated_word, words in zip(df1['translated_word'], df1['similar_words_collection']):\n",
        "  if translated_word in words:\n",
        "    recall_values.append(1)\n",
        "    reciprocal_rank.append(1 / (words.index(translated_word) + 1))\n",
        "  else:\n",
        "    recall_values.append(0)\n",
        "    reciprocal_rank.append(0)\n",
        "\n",
        "df1['recall_value'] = recall_values\n",
        "df1['reciprocal_rank'] = reciprocal_rank\n",
        "mean_reciprocal_rank_de = sum(df1['reciprocal_rank'])/len(df1)\n",
        "print(mean_reciprocal_rank_de)"
      ],
      "metadata": {
        "id": "tM51D6-X_GGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2935c4-afec-42e5-cef6-58e53b554467"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2797308513849228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "xkqp0ooouWW2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6afad968-01cb-466d-f373-259b685e1126"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word                           similar_words_collection  \\\n",
              "0           a  [مماثل, صغير, بسيط, وهو, بديل, تجريبي, نموذجية...   \n",
              "1      aachen  [بريمن, هامبورغ, ستراسبورغ, شتوتغارت, ميونخ, ب...   \n",
              "2     aalborg  [كوبنهاغن, الدنمارك, كيل, ستوكهولم, توركو, ليي...   \n",
              "3      aarhus  [ستوكهولم, كوبنهاغن, الدنمارك, لييج, هامبورغ, ...   \n",
              "4       aaron  [دانييل, هارون, جوناثان, جويل, داني, صموئيل, ج...   \n",
              "...       ...                                                ...   \n",
              "4097     zinc  [الزنك, النحاس, المنغنيز, الألمنيوم, القصدير, ...   \n",
              "4098     zion  [صهيون, الكرمل, يهودا, صموئيل, المخلص, يهوذا, ...   \n",
              "4099  zionism  [الصهيونية, الصهيوني, صهيونية, يهودا, موشيه, ا...   \n",
              "4100   zombie  [كراش, رعب, الوحش, وحش, الرعب, ديد, مصاص, الجو...   \n",
              "4101    zorro  [زورو, سوبرمان, شبح, الغول, باتمان, الشبح, صائ...   \n",
              "\n",
              "     translated_word  recall_value  reciprocal_rank  \n",
              "0                  a             0         0.000000  \n",
              "1                آخن             0         0.000000  \n",
              "2             آلبورغ             0         0.000000  \n",
              "3              آرهوس             0         0.000000  \n",
              "4              هارون             1         0.500000  \n",
              "...              ...           ...              ...  \n",
              "4097             زنك             0         0.000000  \n",
              "4098           صهيون             1         1.000000  \n",
              "4099         صهيونية             1         0.333333  \n",
              "4100           زومبي             0         0.000000  \n",
              "4101            زورو             1         1.000000  \n",
              "\n",
              "[4102 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2553862f-a1c5-4fae-8d0b-0d9c185f0eb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>similar_words_collection</th>\n",
              "      <th>translated_word</th>\n",
              "      <th>recall_value</th>\n",
              "      <th>reciprocal_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>[مماثل, صغير, بسيط, وهو, بديل, تجريبي, نموذجية...</td>\n",
              "      <td>a</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aachen</td>\n",
              "      <td>[بريمن, هامبورغ, ستراسبورغ, شتوتغارت, ميونخ, ب...</td>\n",
              "      <td>آخن</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aalborg</td>\n",
              "      <td>[كوبنهاغن, الدنمارك, كيل, ستوكهولم, توركو, ليي...</td>\n",
              "      <td>آلبورغ</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aarhus</td>\n",
              "      <td>[ستوكهولم, كوبنهاغن, الدنمارك, لييج, هامبورغ, ...</td>\n",
              "      <td>آرهوس</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aaron</td>\n",
              "      <td>[دانييل, هارون, جوناثان, جويل, داني, صموئيل, ج...</td>\n",
              "      <td>هارون</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4097</th>\n",
              "      <td>zinc</td>\n",
              "      <td>[الزنك, النحاس, المنغنيز, الألمنيوم, القصدير, ...</td>\n",
              "      <td>زنك</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4098</th>\n",
              "      <td>zion</td>\n",
              "      <td>[صهيون, الكرمل, يهودا, صموئيل, المخلص, يهوذا, ...</td>\n",
              "      <td>صهيون</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099</th>\n",
              "      <td>zionism</td>\n",
              "      <td>[الصهيونية, الصهيوني, صهيونية, يهودا, موشيه, ا...</td>\n",
              "      <td>صهيونية</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4100</th>\n",
              "      <td>zombie</td>\n",
              "      <td>[كراش, رعب, الوحش, وحش, الرعب, ديد, مصاص, الجو...</td>\n",
              "      <td>زومبي</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4101</th>\n",
              "      <td>zorro</td>\n",
              "      <td>[زورو, سوبرمان, شبح, الغول, باتمان, الشبح, صائ...</td>\n",
              "      <td>زورو</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4102 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2553862f-a1c5-4fae-8d0b-0d9c185f0eb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2553862f-a1c5-4fae-8d0b-0d9c185f0eb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2553862f-a1c5-4fae-8d0b-0d9c185f0eb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsXoZaVsYMXR"
      },
      "source": [
        "The list of Wikipedia headwords is short enough that a linear scan through the non-English language embeddings takes some time but is feasible. In a production system, you could index the word embeddings using SimHash or some other locality sensitive hashing scheme, as we discussed for duplicate detection, to speed up this process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of CrossLanguageEmbeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}